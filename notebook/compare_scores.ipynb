{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4b10ac2-88fb-4b89-a82f-ef8f4794272f",
   "metadata": {},
   "source": [
    "# Compare scores\n",
    "\n",
    "Compare evaluation scores across two models\n",
    "\n",
    "\"Old\" vs. \"new\" refer to before/after implementing expansion of condensed formulas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc99a008-44f7-43ab-82b9-39f2bd5378cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4fcce73-96ab-465c-a476-0034baafc4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLEF\n",
      "GRAPH SMILES\n",
      "1:\n",
      "Old graph to smiles: 0.8407258064516129 New graph to smiles: 0.8336693548387096\n",
      "2:\n",
      "Old graph to smiles: 0.8397177419354839 New graph to smiles: 0.8417338709677419\n",
      "POST SMILES\n",
      "1:\n",
      "Old tokenizer: 80.85 New tokenizer + old post: 0.844758064516129 New tokenizer + new post: 0.8377016129032258\n",
      "2:\n",
      "Old postprocessing: 0.8417338709677419 New postprocessing: 0.84375\n",
      "\n",
      "\n",
      "JPO\n",
      "GRAPH SMILES\n",
      "1:\n",
      "Old graph to smiles: 0.4777777777777778 New graph to smiles: 0.4822222222222222\n",
      "2:\n",
      "Old graph to smiles: 0.4777777777777778 New graph to smiles: 0.4777777777777778\n",
      "POST SMILES\n",
      "1:\n",
      "Old tokenizer: 0.0 New tokenizer + old post: 0.47555555555555556 New tokenizer + new post: 0.48\n",
      "2:\n",
      "Old postprocessing: 0.47555555555555556 New postprocessing: 0.47555555555555556\n",
      "\n",
      "\n",
      "UOB\n",
      "GRAPH SMILES\n",
      "1:\n",
      "Old graph to smiles: 0.8564459930313589 New graph to smiles: 0.8564459930313589\n",
      "2:\n",
      "Old graph to smiles: 0.8092334494773519 New graph to smiles: 0.8092334494773519\n",
      "POST SMILES\n",
      "1:\n",
      "Old tokenizer: 84.95 New tokenizer + old post: 0.8574912891986063 New tokenizer + new post: 0.8574912891986063\n",
      "2:\n",
      "Old postprocessing: 0.8094076655052265 New postprocessing: 0.8094076655052265\n",
      "\n",
      "\n",
      "USPTO\n",
      "GRAPH SMILES\n",
      "1:\n",
      "Old graph to smiles: 0.9054030424899457 New graph to smiles: 0.9045287637698899\n",
      "2:\n",
      "Old graph to smiles: 0.9048784752579122 New graph to smiles: 0.9040041965378562\n",
      "POST SMILES\n",
      "1:\n",
      "Old tokenizer: 90.16 New tokenizer + old post: 0.9068018884420354 New tokenizer + new post: 0.9059276097219794\n",
      "2:\n",
      "Old postprocessing: 0.9045287637698899 New postprocessing: 0.9036544850498339\n",
      "\n",
      "\n",
      "staker\n",
      "GRAPH SMILES\n",
      "1:\n",
      "Old graph to smiles: 0.85614 New graph to smiles: 0.85762\n",
      "2:\n",
      "Old graph to smiles: 0.85372 New graph to smiles: 0.85524\n",
      "POST SMILES\n",
      "1:\n",
      "Old tokenizer: 82.61 New tokenizer + old post: 0.8558 New tokenizer + new post: 0.85708\n",
      "2:\n",
      "Old postprocessing: 0.85318 New postprocessing: 0.85454\n",
      "\n",
      "\n",
      "acs\n",
      "GRAPH SMILES\n",
      "1:\n",
      "Old graph to smiles: 0.7843137254901961 New graph to smiles: 0.7843137254901961\n",
      "2:\n",
      "Old graph to smiles: 0.8235294117647058 New graph to smiles: 0.8235294117647058\n",
      "POST SMILES\n",
      "1:\n",
      "Old tokenizer: 82.35 New tokenizer + old post: 0.7941176470588235 New tokenizer + new post: 0.7941176470588235\n",
      "2:\n",
      "Old postprocessing: 0.8235294117647058 New postprocessing: 0.8235294117647058\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "datasets = ['CLEF', 'JPO', 'UOB', 'USPTO', 'staker', 'acs']\n",
    "# eval_files_1 = ['../output/uspto/swin_base_aux_200k_new1/eval_scores_CLEF_sub_R.json',\n",
    "#                     '../output/uspto/swin_base_aux_200k_new1/eval_scores_JPO_sub_R.json',\n",
    "#                     '../output/uspto/swin_base_aux_200k_new1/eval_scores_UOB_sub_R.json',\n",
    "#                     '../output/uspto/swin_base_aux_200k_new1/eval_scores_USPTO_sub_R.json',\n",
    "#                     '../output/uspto/swin_base_aux_200k_new1/eval_scores_staker_sub_R.json',\n",
    "#                     '../output/uspto/swin_base_aux_200k_new1/eval_scores_acs_sub_R.json'\n",
    "# ]\n",
    "eval_files_1 = ['../output/uspto/swin_base_aux_200k_new1_augdata/eval_scores_CLEF_sub_R.json',\n",
    "                    '../output/uspto/swin_base_aux_200k_new1_augdata/eval_scores_JPO_sub_R.json',\n",
    "                    '../output/uspto/swin_base_aux_200k_new1_augdata/eval_scores_UOB_sub_R.json',\n",
    "                    '../output/uspto/swin_base_aux_200k_new1_augdata/eval_scores_USPTO_sub_R.json',\n",
    "                    '../output/uspto/swin_base_aux_200k_new1_augdata/eval_scores_staker_sub_R.json',\n",
    "                    '../output/uspto/swin_base_aux_200k_new1_augdata/eval_scores_acs_sub_R.json'\n",
    "]\n",
    "eval_files_2 = ['../output/uspto/swin_base_aux_200k_new1_augdata1/eval_scores_CLEF_sub_R.json',\n",
    "                    '../output/uspto/swin_base_aux_200k_new1_augdata1/eval_scores_JPO_sub_R.json',\n",
    "                    '../output/uspto/swin_base_aux_200k_new1_augdata1/eval_scores_UOB_sub_R.json',\n",
    "                    '../output/uspto/swin_base_aux_200k_new1_augdata1/eval_scores_USPTO_sub_R.json',\n",
    "                    '../output/uspto/swin_base_aux_200k_new1_augdata1/eval_scores_staker_sub_R.json',\n",
    "                    '../output/uspto/swin_base_aux_200k_new1_augdata1/eval_scores_acs_sub_R.json'\n",
    "]\n",
    "old_tokenizer = [80.85, 0., 84.95, 90.16, 82.61, 82.35]\n",
    "\n",
    "for dataset, eval_file_1, eval_file_2, old_token in zip(datasets, eval_files_1, eval_files_2, old_tokenizer):\n",
    "    with open(eval_file_1, 'r') as f:\n",
    "        eval_res_1 = json.load(f)\n",
    "    with open(eval_file_2, 'r') as f:\n",
    "        eval_res_2 = json.load(f)\n",
    "    print(dataset)\n",
    "    print(\"GRAPH SMILES\")\n",
    "    print(\"1:\")\n",
    "    print(\"Old graph to smiles:\", eval_res_1['old_graph_smiles'], \"New graph to smiles:\", eval_res_1['graph_smiles'])\n",
    "    print(\"2:\")\n",
    "    print(\"Old graph to smiles:\", eval_res_2['old_graph_smiles'], \"New graph to smiles:\", eval_res_2['graph_smiles'])\n",
    "    print(\"POST SMILES\")\n",
    "    print(\"1:\")\n",
    "    print(\"Old tokenizer:\", old_token, \"New tokenizer + old post:\", eval_res_1['old_post_smiles'], \"New tokenizer + new post:\", eval_res_1['post_smiles'])\n",
    "    print(\"2:\")\n",
    "    print(\"Old postprocessing:\", eval_res_2['old_post_smiles'], \"New postprocessing:\", eval_res_2['post_smiles'])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd3d09c-18ac-411b-b9b6-09e8787abdaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
